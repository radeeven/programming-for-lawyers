
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Retrieval-Augmented Generation &#8212; Programming for Lawyers</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/RAG';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Appendix: Unsupervised Learning" href="unsupervised_learning.html" />
    <link rel="prev" title="Supervised Learning" href="supervised_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/uio_logo_small.svg" class="logo__image only-light" alt="Programming for Lawyers - Home"/>
    <img src="../_static/uio_logo_small.svg" class="logo__image only-dark pst-js-only" alt="Programming for Lawyers - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_basics.html">Programming basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_decisions.html">Decisions</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_lists.html">Lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="03b_loops.html">Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_functions.html">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="04b_dictionaries.html">Dictionaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_files_exceptions.html">Files and Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tabular_data.html">Tabular Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="sorting_filtering.html">Sorting, Filtering Data and Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine_learning.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="supervised_learning.html">Supervised Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Retrieval-Augmented Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="unsupervised_learning.html">Appendix: Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="JSON-APIs.html">Appendix: JSON and Web APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="standalone-programs.html">Appendix: Standalone Programs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://jupyterhub.uio.no/hub/user-redirect/git-pull?repo=https%3A//github.com/UiO-CELL/programming-for-lawyers&urlpath=tree/programming-for-lawyers/docs/RAG.ipynb&branch=master" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on JupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="JupyterHub logo" src="../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/UiO-CELL/programming-for-lawyers/blob/master/docs/RAG.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/UiO-CELL/programming-for-lawyers" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/UiO-CELL/programming-for-lawyers/edit/master/docs/RAG.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/UiO-CELL/programming-for-lawyers/issues/new?title=Issue%20on%20page%20%2Fdocs/RAG.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/docs/RAG.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Retrieval-Augmented Generation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installing-software">Installing Software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-language-model">The Language Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-storage-location">Model Storage Location</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#huggingface-login">HuggingFace Login</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model">The Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-language-model">Using the Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-vectorizer">The Vectorizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-documents">Loading the Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-documents">Splitting the Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-document-index">The Document Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-a-prompt">Making a Prompt</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-the-chatbot">Making the «Chatbot»</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#asking-the-chatbot">Asking the «Chatbot»</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="retrieval-augmented-generation">
<h1>Retrieval-Augmented Generation<a class="headerlink" href="#retrieval-augmented-generation" title="Link to this heading">#</a></h1>
<p>Retrieval-Augmented Generation (RAG) is a method for including (parts of) matching documents as context for questions to a Large Language Model (LLM).
This can help reduce hallucinations and wrong answers.
A system for RAG has two parts: a document database with a search index and a large language model.</p>
<p>When the user asks a question, the question is handled in two stages.
First, the question is used as a search query for the document database.
The search results are then sent together with the question to the LLM.
The LLM is prompted to answer the question based on the context in the search results.</p>
<p>We will use <a class="reference external" href="https://www.langchain.com/">LangChain</a>, an open-source library for making applications with LLMs.
This chapter was inspired by the article
<a class="reference external" href="https://medium.com/&#64;jiangan0808/retrieval-augmented-generation-rag-with-open-source-hugging-face-llms-using-langchain-bd618371be9d">Retrieval-Augmented Generation (RAG) with open-source Hugging Face LLMs using LangChain</a>.</p>
<section id="installing-software">
<h2>Installing Software<a class="headerlink" href="#installing-software" title="Link to this heading">#</a></h2>
<p>We’ll need to install some libraries first:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>sentence-transformers<span class="w"> </span>huggingface-hub<span class="w"> </span>faiss-cpu<span class="w"> </span>sentencepiece<span class="w"> </span>protobuf<span class="w"> </span>langchain<span class="w"> </span>langchain-community<span class="w"> </span>pypdf
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-language-model">
<h2>The Language Model<a class="headerlink" href="#the-language-model" title="Link to this heading">#</a></h2>
<p>We’ll use models from <a class="reference external" href="https://huggingface.co/">HuggingFace</a>, a website that has tools and models for machine learning.
We’ll use the open-source LLM <a class="reference external" href="https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407">mistralai/Mistral-Nemo-Instruct-2407</a>.
This model has 12 billion parameters.
For comparison, one of the largest LLMs at the time of writing is Llama 3.1, with 405 billion parameters.
Still, Mistral-Nemo-Instruct is around 25 GB, which makes it a quite large model.
To run it, we must have a GPU with at least 25 GB memory.
It can also be run without a GPU, but that will be much slower.</p>
<section id="model-storage-location">
<h3>Model Storage Location<a class="headerlink" href="#model-storage-location" title="Link to this heading">#</a></h3>
<p>We must download the model we want to use.
Because of the requirements mentioned above, we run our program on the <a class="reference external" href="https://www.uio.no/english/services/it/research/hpc/fox/">Fox</a> high-performance computer at UiO.
We must set the location where our program should store the models that we download from HuggingFace:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">env</span> HF_HOME=/fp/projects01/ec367/huggingface/cache/
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you run the program locally on your own computer, you might not need to set <code class="docutils literal notranslate"><span class="pre">HF_HOME</span></code>.</p>
</div>
</section>
<section id="huggingface-login">
<h3>HuggingFace Login<a class="headerlink" href="#huggingface-login" title="Link to this heading">#</a></h3>
<p>Even though the model Mistral-Nemo-Instruct-2407 is open source, we must log in to HuggingFace to download it.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">login</span>
<span class="n">login</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-model">
<h3>The Model<a class="headerlink" href="#the-model" title="Link to this heading">#</a></h3>
<p>Now, we are ready to download and use the model.
To use the model, we create a <em>pipeline</em>.
A pipeline can consist of several processing steps, but in this case, we only need one step.
We can use the method <code class="docutils literal notranslate"><span class="pre">HuggingFacePipeline.from_model_id()</span></code>, which automatically downloads the specified model from HuggingFace.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="o">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;mistralai/Mistral-Nemo-Instruct-2407&#39;</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s1">&#39;text-generation&#39;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;max_new_tokens&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
        <span class="s1">&#39;temperature&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
        <span class="s1">&#39;num_beams&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s1">&#39;do_sample&#39;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "02c52f233cdb43fd8b8882200e48caab", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="admonition-pipeline-arguments admonition">
<p class="admonition-title">Pipeline Arguments</p>
<p>We give some arguments to the pipeline:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_id</span></code>: the name of the  model on HuggingFace</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task</span></code>:  the task you want to use the model for,  other alternatives are  translation and summarization</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code>: the GPU hardware device to use. If we don’t specify a device, no GPU will be used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pipeline_kwargs</span></code>: additional parameters that are passed to the model.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">max_new_tokens</span></code>: maximum length of the generated text</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">do_sample</span></code>: by default, the most likely next word is chosen.  This makes the output deterministic. We can introduce some randomness by sampling among the  most likely words instead.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">temperature</span></code>: the temperature controls the statistical <em>distribution</em> of the next word and is usually between 0 and 1. A low temperature increases the probability of common words. A high temperature increases the probability of outputting a rare word. Model makers often recommend a temperature setting, which we can use as a starting point.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_beams</span></code>: by default the model works with a single sequence of  tokens/words. With beam search, the program  builds multiple sequences at the same time, and then selects the best one in the end.</p></li>
</ul>
</li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you’re working on a computer with less memory, you might need to try a smaller model.
You can try for example <code class="docutils literal notranslate"><span class="pre">mistralai/Mistral-7B-Instruct-v0.3</span></code> or <code class="docutils literal notranslate"><span class="pre">meta-llama/Llama-3.2-1B-Instruct</span></code>. The latter has only 1 billion parameters, and might be possible to use on a laptop, depending on how much memory it has.</p>
<p>If you use models from Meta, you might need to set <code class="docutils literal notranslate"><span class="pre">pad_token_id</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>llm.pipeline.tokenizer.pad_token_id = llm.pipeline.tokenizer.eos_token_id
</pre></div>
</div>
</div>
</section>
</section>
<section id="using-the-language-model">
<h2>Using the Language Model<a class="headerlink" href="#using-the-language-model" title="Link to this heading">#</a></h2>
<p>Now, the language model is ready to use.
Let’s try to use only the language model without RAG.
We can send it a query:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;what are the main problems with bitcoin?&#39;</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>what are the main problems with bitcoin? Bitcoin has several challenges and criticisms, including:

1. **Volatility**: Bitcoin&#39;s price is highly volatile, making it less suitable as a medium of exchange for everyday transactions. Its value can fluctuate significantly over short periods, which can make it difficult to use for purchasing goods and services.

2. **Scalability**: Bitcoin&#39;s network can only process a limited number of transactions per second (around 7), which can lead to slower transaction times and higher fees during periods of heavy usage. This is often referred to as the &quot;block size debate.&quot;

3. **Energy Consumption**: Bitcoin&#39;s proof-of-work (PoW) consensus mechanism requires a large amount of energy to secure the network. This has led to concerns about its environmental impact. Some estimates suggest that Bitcoin&#39;s energy consumption is comparable to that of entire countries.

4. **Regulation**: Bitcoin&#39;s decentralized nature makes it difficult for governments to regulate. While this is often seen as a strength, it also means that there&#39;s no central authority to protect users if something goes wrong. This has led to concerns about consumer protection and money laundering.

5. **Security**: While Bitcoin&#39;s blockchain is secure, individual users&#39; bitcoins can be stolen or lost if they don&#39;t properly secure their private keys. There have also been instances of exchanges being hacked, leading to significant losses for users.

6. **Adoption**: For Bitcoin to become a widely used currency, it needs to be adopted by a large number of people
</pre></div>
</div>
</div>
</div>
<p>This answer was generated based only on the information contained in the language model.
To improve the accuracy of the answer, we can provide the language model with additional context for our query.
To do that, we must load our document collection.</p>
</section>
<section id="the-vectorizer">
<h2>The Vectorizer<a class="headerlink" href="#the-vectorizer" title="Link to this heading">#</a></h2>
<p>Text must be <a class="reference internal" href="machine_learning.html#vectorizing"><span class="std std-ref">vectorized</span></a> before it can be processed.
Our HuggingFace pipeline will do that automatically for the large language model.
But we must make a vectorizer for the search index for our documents database.
We use a vectorizer called a word embedding model from HuggingFace.
Again, the HuggingFace library will automatically download the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceBgeEmbeddings</span>

<span class="n">huggingface_embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceBgeEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;BAAI/bge-m3&#39;</span><span class="p">,</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda:0&#39;</span><span class="p">},</span>
    <span class="c1">#or: model_kwargs={&#39;device&#39;:&#39;cpu&#39;},</span>
    <span class="n">encode_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;normalize_embeddings&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-embeddings-arguments admonition">
<p class="admonition-title">Embeddings Arguments</p>
<p>These are the arguments to the embedding model:</p>
<ul class="simple">
<li><p>‘model_name’: the name of the model on HuggingFace</p></li>
<li><p>‘device’:  the hardware device to use, either a GPU or CPU</p></li>
<li><p>‘normalize_embeddings’:  embeddings can have different magnitudes. Normalizing the embeddings makes their magnitudes equal.</p></li>
</ul>
</div>
</section>
<section id="loading-the-documents">
<h2>Loading the Documents<a class="headerlink" href="#loading-the-documents" title="Link to this heading">#</a></h2>
<p>We use a document loader from the LangChain library
to load all the PDFs in the  folder called  <code class="docutils literal notranslate"><span class="pre">documents</span></code>.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">PyPDFDirectoryLoader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">PyPDFDirectoryLoader</span><span class="p">(</span><span class="s1">&#39;./documents/&#39;</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The document loader loads each PDF page as a separate ‘document’.
This is partly for technical reasons because that is the way PDFs are structured.
But we would want to split our documents into smaller chunks anyway.
We can check how long our documents are.
First, we define a function for this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statistics</span>
<span class="k">def</span> <span class="nf">average_length</span><span class="p">(</span><span class="n">documents</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">statistics</span><span class="o">.</span><span class="n">fmean</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we can use this function on our documents:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of documents: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="si">}</span><span class="s1">, average document length: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">average_length</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Maximum document length: &#39;</span><span class="p">,</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of documents: 213, average document length: 2199
Maximum document length:  9839
</pre></div>
</div>
</div>
</div>
<p>We can examine one of the documents:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>page_content=&#39;Pr
ogramming Languages and Law
A Research Agenda
James Grimmelmann
james.grimmelmann@cornell.edu
Cornell University
Law School and Cornell Tech
New York City, NY, USA
ABSTRACT
If code is law, then the language of law is a programming lan-
guage.Lawyersandlegalscholarscanlearnaboutlawbystudying
programming-language theory, and programming-language tools
can be usefully applied to legal problems. This article surveys the
history of research into programming languages and law and pre-
sents ten promising avenues for future efforts. Its goals are to ex-
plain how the combination of programming languages and law is
distinctive within the broader field of computer science and law,
and to demonstrate with concrete examples the remarkable power
of programming-language concepts in this new domain.
CCS CONCEPTS
•Software and its engineering →General programming lan-
guages; Domainspecificlanguages ;•Socialandprofessional
topics →Computing / technology policy.
KEYWORDS
programming languages, law
ACM Reference Format:
James Grimmelmann. 2022. Programming Languages and Law: A Research
Agenda.In Proceedings of the 2022 Symposium on Computer Science and Law
(CSLAW ’22), November 1–2, 2022, Washington, DC, USA. ACM, New York,
NY, USA, 11 pages. https://doi.org/10.1145/3511265.3550447
1 INTRODUCTION
Computer science contains multitudes. It ranges from pure math-
ematics to quantum physics, from the heights of theory to the
depths of systems engineering.
Some of its subfields speak to urgent problems law faces. Crim-
inal procedure [60] and national security law [27] cannot regulate
the world as it exists without taking account of whether, when,
and how data can be kept private. Other subfields provide new
perspectives on law. The “law as data” movement [9, 75] uses com-
putational methods like topic modeling and decision-tree learning
to analyze legal datasets in subjects as diverse as trademark in-
fringement, [17] judicial rhetoric, [74] and the network structure
of the United States Code. [59]
This
work is licensed under a Creative Commons Attribu-
tion International 4.0 License.
CSLAW ’22, November 1–2, 2022, Washington, DC, USA
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9234-1/22/11.
https://doi.org/10.1145/3511265.3550447Iwouldliketoarguethatthecomputer-sciencefieldof program-
ming-language (PL) theory speaks to law in both of these senses.
Notonlyisitindispensableforansweringcertainkindsofpractical
legal questions, but its application can “illuminate the entire law.”
[36] Just as microeconomics provides a new and illuminating way
to think about rights and remedies, and just as corpus linguistics
provides a new and illuminating way to think about legal inter-
pretation, PL theory provides new and illuminating ways to think
about familiar issues from all across the law.
Consider, for example, the M++ project to formalize French tax
law (described in more detail in Section 2.2). M++ is distinguished
from the kind of routine systems engineering that tax authorities
around the world perform on their computer systems by its rig-
orous use of PL theory to design a new programming language
for describing the provisions of the French tax code. On the one
hand, M++ is useful because it is a clean, modern language that
is amenable to correctness proofs, improving the reliability of tax
computations. On the other hand, M++ programs mirror the struc-
ture of the tax laws they formalize. Instead of treating the rules of
tax law as an ad hocdesign document, M++ treats the tax code as
though they were itself a program, one meant to be “executed” by
lawyers and accountants. The goal is not just to do the same thing
as the tax code, but to do it in the same way, section by section,
clause by clause.
To generalize, PL theory has something unique to offer law be-
cause there is a crucial similarity between lawyers and program-
mers: the way they use words. Computer science and law are both
linguistic professions. Programmers and lawyers use language to
create,manipulate,andinterpretcomplexabstractions.Aprogram-
mer who uses the right words in the right way makes a computer
do something. A lawyer who uses the right words in the right way
changes people’s rights and obligations. There is a nearly exact
analogy between the text of a program and the text of a law.
Thisparallel createsaunique opportunity for PLtheory as a dis-
cipline to contribute to law. Some CS subfields, such as artificial in-
telligence (AI), deal with legal structures. Others, such as natural
language processing (NLP), deal with legal language. But only PL
theory provides a principled, systematic framework to analyze le-
gal structures in terms of the linguistic expressions lawyers use to
create them. PL abstractions have an unmatched expressive power
in capturing the linguistic abstractions of law.
Over a decade ago, Paul Ohm proposed a new research agenda
for“computerprogrammingandlaw,”describingindetailthevalue
of executable code for legal scholarship: by gathering and analyz-
ing information about the law more efficiently, by communicating
155
&#39; metadata={&#39;source&#39;: &#39;documents/Grimmelmann - 2022 - Programming Languages and Law A Research Agenda.pdf&#39;, &#39;page&#39;: 0}
</pre></div>
</div>
</div>
</div>
</section>
<section id="splitting-the-documents">
<h2>Splitting the Documents<a class="headerlink" href="#splitting-the-documents" title="Link to this heading">#</a></h2>
<p>Since we are only using PDFs with quite short pages, we can use them as they are.
Other, longer documents, for example the documents or webpages, we might need to split into chunks.
We can use a text splitter from LangChain to split documents.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span> <span class="c1">#  or less, like 700 for models with smaller context windows</span>
    <span class="n">chunk_overlap</span>  <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-text-splitter-arguments admonition">
<p class="admonition-title">Text  Splitter Arguments</p>
<p>These are the arguments to the text splitter:</p>
<ul class="simple">
<li><p>‘chunk_size’: the number of tokens in each chunk.  Not necessarily the same as the number of words.</p></li>
<li><p>‘chunk_overlap’: the number of tokens that are included in both chunks where the text is split.</p></li>
</ul>
</div>
<p>We can check if the average and maximum document length has changed:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of documents: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="si">}</span><span class="s1">, average document length: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">average_length</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Maximum document length: &#39;</span><span class="p">,</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of documents: 226, average document length: 2075
Maximum document length:  4991
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-document-index">
<h2>The Document Index<a class="headerlink" href="#the-document-index" title="Link to this heading">#</a></h2>
<p>Next, we make a search index for our documents.
We will use this index for the retrieval part of ‘Retrieval-Augmented Generation’.
We use the open-source library <a class="reference external" href="https://github.com/facebookresearch/faiss">FAISS</a>
(Facebook AI Similarity Search) through LangChain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">huggingface_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>FAISS can find documents that match a search query:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;what are the main problems with bitcoin?&#39;</span>
<span class="n">relevant_documents</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of documents found: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">relevant_documents</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of documents found: 4
</pre></div>
</div>
</div>
</div>
<p>We can display the first document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">relevant_documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Yale Information Society Project 8 8 problems. Thefts, bugs, and other problems can be undone if detected in time. Cryptocurrencies lack this critical feature. This is why cryptocurrency thefts, as a fraction of the available currency, are orders of magnitude more common and severe than thefts in the normal financial system.  The largest significant electronic bank heist, targeting the Bank of Bangladesh, managed to steal roughly $100 million.8 Cryptocurrency hacks of similar magnitude are almost a monthly occurrence; indeed, in the largest cryptocurrency hack on record, of Axie Infinity’s “Ronin Bridge,” hackers stole over $600 million.9 This ease of theft is inherent in the very nature of cryptocurrency. Stealing $10 million in physical cash requires that someone break into a secure location and move 100 kilograms of physical paper. Stealing $10 million in a traditional bank transfer requires both breaking into the bank’s computer and also quickly moving the money through a series of accounts to hide its origin, such that the victim’s bank cannot undo the theft. Stealing $10 million in cryptocurrency controlled by a computer, on the other hand, requires compromising the computer but—critically—the victim can’t recover the money.10 This creates significant friction in buying cryptocurrencies. Someone who wishes to sell cryptocurrencies cannot accept a conventional electronic payment. Instead they either have to have an established relationship with the buyer (to know the buyer poses an acceptable credit risk), accept cash, or accept an electronic payment and then wait for a few days.11 This drives up the price of buying cryptocurrency as all three options (validating credit risk, accepting cache, or waiting) incur additional expenses not present in other payment systems. Furthermore, the actual cryptocurrency transactions themselves can be surprisingly expensive.12 In order to act as a limit on spam transactions, where someone creates a huge number of useless transitions that need to be validated, slowing down the transaction verification process, any given cryptocurrency allows only a limited number of transactions per block in the blockchain. When the desired number of transactions is below this threshold, transactions are nearly free. But if the desired transaction rate exceeds this threshold, then prices can spiral as a fee auction is used to select which transactions to process due to the inelastic supply of available slots.
</pre></div>
</div>
</div>
</div>
<p>For our RAG application we need to access the search engine through an interface called a retriever:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">retriever</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-retriever-arguments admonition">
<p class="admonition-title">Retriever Arguments</p>
<p>These are the arguments to the retriever:</p>
<ul class="simple">
<li><p>‘k’: the number of documents to return (kNN search)</p></li>
</ul>
</div>
</section>
<section id="making-a-prompt">
<h2>Making a Prompt<a class="headerlink" href="#making-a-prompt" title="Link to this heading">#</a></h2>
<p>We can use a <em>prompt</em> to tell the language model how to answer.
The prompt should contain a few short, helpful instructions.
In addition, we provide placeholders for the context and the question.
LangChain replaces these with the actual context and question when we execute a query.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;You are an assistant for question-answering tasks.</span>
<span class="s1">Use the following pieces of retrieved context to answer the question.</span>
<span class="s1">If you don&#39;t know the answer, just say that you don&#39;t know.</span>
<span class="s1">Keep the answer concise.</span>
<span class="s1">Context: </span><span class="si">{context}</span>

<span class="s1">Question: </span><span class="si">{input}</span>

<span class="s1">Answer:</span>
<span class="s1">&#39;&#39;&#39;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">,</span>
                        <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="making-the-chatbot">
<h2>Making the «Chatbot»<a class="headerlink" href="#making-the-chatbot" title="Link to this heading">#</a></h2>
<p>Now we can use the module <code class="docutils literal notranslate"><span class="pre">create_retrieval_chain</span></code> from LangChain to make an agent for answering questions, a «chatbot».</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_retrieval_chain</span>
<span class="kn">from</span> <span class="nn">langchain.chains.combine_documents</span> <span class="kn">import</span> <span class="n">create_stuff_documents_chain</span>

<span class="n">combine_docs_chain</span> <span class="o">=</span> <span class="n">create_stuff_documents_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
<span class="n">rag_chain</span> <span class="o">=</span> <span class="n">create_retrieval_chain</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">combine_docs_chain</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="asking-the-chatbot">
<h2>Asking the «Chatbot»<a class="headerlink" href="#asking-the-chatbot" title="Link to this heading">#</a></h2>
<p>Now, we can send our query to the chatbot.</p>
<div class="cell tag_scroll-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">rag_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_scroll-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You are an assistant for question-answering tasks.
Use the following pieces of retrieved context to answer the question.
If you don&#39;t know the answer, just say that you don&#39;t know.
Keep the answer concise.
Context: Yale Information Society Project 8 8 problems. Thefts, bugs, and other problems can be undone if detected in time. Cryptocurrencies lack this critical feature. This is why cryptocurrency thefts, as a fraction of the available currency, are orders of magnitude more common and severe than thefts in the normal financial system.  The largest significant electronic bank heist, targeting the Bank of Bangladesh, managed to steal roughly $100 million.8 Cryptocurrency hacks of similar magnitude are almost a monthly occurrence; indeed, in the largest cryptocurrency hack on record, of Axie Infinity’s “Ronin Bridge,” hackers stole over $600 million.9 This ease of theft is inherent in the very nature of cryptocurrency. Stealing $10 million in physical cash requires that someone break into a secure location and move 100 kilograms of physical paper. Stealing $10 million in a traditional bank transfer requires both breaking into the bank’s computer and also quickly moving the money through a series of accounts to hide its origin, such that the victim’s bank cannot undo the theft. Stealing $10 million in cryptocurrency controlled by a computer, on the other hand, requires compromising the computer but—critically—the victim can’t recover the money.10 This creates significant friction in buying cryptocurrencies. Someone who wishes to sell cryptocurrencies cannot accept a conventional electronic payment. Instead they either have to have an established relationship with the buyer (to know the buyer poses an acceptable credit risk), accept cash, or accept an electronic payment and then wait for a few days.11 This drives up the price of buying cryptocurrency as all three options (validating credit risk, accepting cache, or waiting) incur additional expenses not present in other payment systems. Furthermore, the actual cryptocurrency transactions themselves can be surprisingly expensive.12 In order to act as a limit on spam transactions, where someone creates a huge number of useless transitions that need to be validated, slowing down the transaction verification process, any given cryptocurrency allows only a limited number of transactions per block in the blockchain. When the desired number of transactions is below this threshold, transactions are nearly free. But if the desired transaction rate exceeds this threshold, then prices can spiral as a fee auction is used to select which transactions to process due to the inelastic supply of available slots.

JUNE 2018  |   VOL. 61  |   NO. 6  |   COMMUNICATIONS OF THE ACM    23viewpoints
This was not because our Bitcoin 
was stolen from a honeypot, rather the 
graduate student who created the wallet 
maintained a copy and his account was 
compromised. If security experts can’t 
safely keep cryptocurrencies on an Inter -
net-connected computer, nobody can. If 
Bitcoin is the “Internet of money,” what 
does it say that it cannot be safely stored 
on an Internet connected computer?
Bugs can also naturally cause sig-
nificant damage to cryptocurrency 
holdings. Although this potentially can 
affect any cryptocurrency, the biggest 
danger for bugs arises when cryptocur-
rencies are combined with “smart con-
tracts”—programs that are generally 
immutable once deployed and that au-
tomatically execute upon the transfer 
of currency. The most successful plat-
form for these is Ethereum, a crypto-
currency that allows writing programs 
in a language called Solidity.
Bugs in these smart contracts can 
be catastrophic. The first big smart 
contract, the DAO or Decentralized Au -
tonomous Organization, sought to cre -
ate a democratic mutual fund where 
investors could invest their Ethereum 
and then vote on possible investments. 
Approximately 10% of all Ethereum 
ended up in the DAO before someone 
discovered a reentrancy bug that en -
abled the attacker to effectively steal all 
the Ethereum. The only reason this bug 
and theft did not result in global losses 
is that Ethereum developers released a 
new version of the system that effective -
ly undid the theft by altering the sup -
posedly immutable blockchain.
Since then there have been other 
catastrophic bugs in these smart con-
tracts, the biggest one in the Parity 
Ethereum wallet software (see https://
bit.ly/2Fm7je4). The first bug enabled 
the mass theft from “multisignature” 
wallets, which supposedly required 
multiple independent cryptographic 
signatures on transfers as a way to pre-
vent theft. Fortunately, that bug caused 
limited damage because a good thief 
stole most of the money and then re-
turned it to the victims. Yet, the good 
news was limited as a subsequent bug 
rendered all of the new multisignature 
wallets permanently inaccessible, ef-
fectively destroying some $150M in no-
tional value. This buggy code was large-
ly written by Gavin Wood, the creator 
of the Solidity programming language and one of the founders of Ethereum. 
Again, we have a situation where even 
an expert’s efforts fell short.
Individual Economic Risks
Everything about the cryptocurrency 
space is full of bubbles. Since all volatile 
cryptocurrencies are actually substan -
tially inferior for legal purposes, this im -
plies that the actual value as currency is 
effectively $0, so the only store of value 
is in other utility for a distributed trust -
less public append-only ledger.
Yet the Bitcoin blockchain, due to 
consolidation of mining into a few min -
ing pools, does not actually distribute 
trust. Instead the system is effectively 
controlled by less than 10 entities self-
selected by their willingness to consume 
power and anyone using Bitcoin implic -
itly trusts a majority of these few entities. 
Every proof of work blockchain seems to 
experience similar consolidation as the 
more efficient miners inevitably drive out 
less efficient ones. Given the almost trivial 
cost of building a three-transactions-per-
second distributed system with identified 
and trusted entities using cryptographic 
signatures instead of proof of work this 
suggests the utility value for these cryp -
tocurrencies is also effectively $0. This 
means everyone participating in the 
cryptocurrency market is basing the val -
ue only on the price that somebody else 
will pay—no different from tulip bulbs or 
beanie babies—and are all vulnerable to 
substantial and sudden collapse .
But further magnifying the prob-
lem is a large number of scams. There 
is a current trend in “Initial Coin Of-
ferings,” mostly consisting of crypto-
graphic tokens implemented on top 
of an existing cryptocurrencies such as 
Bitcoin or Ethereum. Although claim-
ing to be crowd-sold tokens for pur-
chase of future services, the tradeable 
nature of these tokens has resulted in 
their acting as unregistered securities in a bubble market. There are also or-
ganized groups conducting pump-and-
dump schemes, complete with fancy 
websites, animated advertisements, 
and even placing paper advertisements 
in BART commuter trains in San Fran-
cisco, CA. This market developed large-
ly in absence of regulation, although 
regulators like the U.S. Securities and 
Exchange Commission are finally start-
ing to pay attention.
Likewise, not only is a bubble often 
a natural Ponzi scheme, there are many 
explicit or likely Ponzi schemes. In the 
early days of Bitcoin approximately 10% 
of all Bitcoin were invested in Bitcoin 
Savings and Trust, a Ponzi scheme run 
by a pseudonymous individual known

The Death of Cryptocurrency | Nicholas Weaver 9 Bitcoin is particularly limited in this respect. Due to an early decision to limit spam by restricting the block size to just one megabyte, the Bitcoin network can only process somewhere between three and seven transactions per second worldwide. In comparison, the typical load on the VISA network is 1,700 transactions per second, and VISA has tested the system up to 64,000 transactions per second. During times of congestion, this can lead to the price for Bitcoin transactions reaching $50 or more. Other cryptocurrencies may have higher limits, which naturally leads them to be more vulnerable to spam. High congestion fees ensure that Bitcoin transactions can never be used for everyday, low-value payments. It is inconceivable that consumers would be willing to pay an extra $50 at the grocery store because they went shopping on a Saturday or Sunday afternoon. Cryptocurrency advocates will insist that “layer-two solutions” exist for this problem. They will often point to the Bitcoin “Lightning Network,” a protocol implemented on top of the underlying cryptocurrency, as an example of a solution. Unfortunately these don’t solve the fundamental problem of limited transaction capacity. Lightning works by creating a pre-funded payment channel between the user and a central relayer.13 From there the user can issue or receive payments that pass through a chain of relayers to the recipient. Eventually, a user may close the channel and receive the Bitcoin back onto the main blockchain. Thus, the internal payments no longer need to be recorded on the central blockchain. In creating, adding funds, and closing the channel, the user still needs to conduct a normal Bitcoin transaction. The Lightning network’s ability to create or close channels is limited by Bitcoin’s own transaction limitations. Therefore, Lightning cannot provide scaling as there is still a substantial limit on the number of channels that can be created, funded, or closed per second. The one example where Bitcoin did scale to a significant number of transactions was in El Salvador, though it scaled, ironically, by not actually using Bitcoin to process payments.14 The dictator of El Salvador, President Nayib Bukele, passed a law mandating that Bitcoin, along with the US dollar, would now be considered official currencies and merchants were

Question: what are the main problems with bitcoin?

Answer:
- High risk of theft due to lack of undo feature
- Expensive transactions, especially during congestion
- Limited transaction capacity (3-7 transactions per second)
- Centralization of mining power in few entities
- High number of scams and Ponzi schemes
- Bugs in smart contracts can lead to significant losses
- Not suitable for everyday, low-value payments due to high fees
</pre></div>
</div>
</div>
</div>
<p>This answer contains information about transaction fees from the context.
This information wasn’t in the previous answer, when we queried only the language model without Retrieval-Augmented Generation.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="supervised_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Supervised Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="unsupervised_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Appendix: Unsupervised Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installing-software">Installing Software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-language-model">The Language Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-storage-location">Model Storage Location</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#huggingface-login">HuggingFace Login</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model">The Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-language-model">Using the Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-vectorizer">The Vectorizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-documents">Loading the Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-documents">Splitting the Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-document-index">The Document Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-a-prompt">Making a Prompt</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-the-chatbot">Making the «Chatbot»</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#asking-the-chatbot">Asking the «Chatbot»</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Erik Winge
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>